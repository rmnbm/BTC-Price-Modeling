{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777f4aad",
   "metadata": {},
   "source": [
    "# Analyse BTC daily features\n",
    "\n",
    "Notebook de démonstration pour:\n",
    "- vérifier la qualité des données BTC (btc_features_daily.csv)\n",
    "- créer une cible (close du lendemain)\n",
    "- explorer la corrélation des features\n",
    "- entraîner quelques modèles vus en cours (baseline de persistance, régression linéaire/Ridge, Gradient Boosting, Random Forest)\n",
    "- analyser les résultats et discuter des limites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35074723",
   "metadata": {},
   "source": [
    "## 1. Chargement des données\n",
    "On charge le fichier `btc_features_daily.csv`, on trie par date et on inspecte le taux de valeurs manquantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cf4624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3,973 rows, 52 columns\n",
      "Taux de valeurs manquantes (top 10):\n",
      "timestamp      0.0\n",
      "adj close      0.0\n",
      "stochrsi_k     0.0\n",
      "stochrsi_d     0.0\n",
      "macd           0.0\n",
      "macd_signal    0.0\n",
      "macd_hist      0.0\n",
      "trix_14        0.0\n",
      "trix_signal    0.0\n",
      "atr_14         0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>adj close</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>ret_1</th>\n",
       "      <th>log_ret</th>\n",
       "      <th>ret_5</th>\n",
       "      <th>...</th>\n",
       "      <th>log_vol_chg</th>\n",
       "      <th>cci_20</th>\n",
       "      <th>plus_di_14</th>\n",
       "      <th>minus_di_14</th>\n",
       "      <th>adx_14</th>\n",
       "      <th>roll_skew_20</th>\n",
       "      <th>roll_kurt_20</th>\n",
       "      <th>typ_price</th>\n",
       "      <th>median_price</th>\n",
       "      <th>ohlc4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-24</td>\n",
       "      <td>322.533997</td>\n",
       "      <td>322.533997</td>\n",
       "      <td>334.740997</td>\n",
       "      <td>321.356995</td>\n",
       "      <td>334.385010</td>\n",
       "      <td>15092300</td>\n",
       "      <td>-0.035980</td>\n",
       "      <td>-0.036644</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093663</td>\n",
       "      <td>-55.910258</td>\n",
       "      <td>16.714946</td>\n",
       "      <td>30.030404</td>\n",
       "      <td>25.159419</td>\n",
       "      <td>0.074377</td>\n",
       "      <td>-0.783043</td>\n",
       "      <td>326.210663</td>\n",
       "      <td>328.048996</td>\n",
       "      <td>328.254250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-25</td>\n",
       "      <td>319.007996</td>\n",
       "      <td>319.007996</td>\n",
       "      <td>322.670013</td>\n",
       "      <td>316.958008</td>\n",
       "      <td>322.286011</td>\n",
       "      <td>9883640</td>\n",
       "      <td>-0.010932</td>\n",
       "      <td>-0.010992</td>\n",
       "      <td>-0.033180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.423304</td>\n",
       "      <td>-65.674105</td>\n",
       "      <td>16.168300</td>\n",
       "      <td>31.566923</td>\n",
       "      <td>25.666490</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>-0.483404</td>\n",
       "      <td>319.545339</td>\n",
       "      <td>319.814011</td>\n",
       "      <td>320.230507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-26</td>\n",
       "      <td>327.924011</td>\n",
       "      <td>327.924011</td>\n",
       "      <td>331.424011</td>\n",
       "      <td>316.627014</td>\n",
       "      <td>319.152008</td>\n",
       "      <td>16410500</td>\n",
       "      <td>0.027949</td>\n",
       "      <td>0.027566</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507041</td>\n",
       "      <td>-38.540179</td>\n",
       "      <td>19.762835</td>\n",
       "      <td>28.927653</td>\n",
       "      <td>25.177641</td>\n",
       "      <td>0.130736</td>\n",
       "      <td>-0.852232</td>\n",
       "      <td>325.325012</td>\n",
       "      <td>324.025513</td>\n",
       "      <td>323.781761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-27</td>\n",
       "      <td>315.863007</td>\n",
       "      <td>315.863007</td>\n",
       "      <td>328.911011</td>\n",
       "      <td>312.630005</td>\n",
       "      <td>327.583008</td>\n",
       "      <td>15185200</td>\n",
       "      <td>-0.036780</td>\n",
       "      <td>-0.037473</td>\n",
       "      <td>-0.048279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077600</td>\n",
       "      <td>-47.473235</td>\n",
       "      <td>17.981409</td>\n",
       "      <td>28.533062</td>\n",
       "      <td>24.999572</td>\n",
       "      <td>0.267018</td>\n",
       "      <td>-0.988402</td>\n",
       "      <td>319.134674</td>\n",
       "      <td>320.770508</td>\n",
       "      <td>321.246758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>317.239014</td>\n",
       "      <td>317.239014</td>\n",
       "      <td>320.028015</td>\n",
       "      <td>311.078003</td>\n",
       "      <td>316.160004</td>\n",
       "      <td>11676600</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>-0.051806</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262734</td>\n",
       "      <td>-47.802507</td>\n",
       "      <td>17.070467</td>\n",
       "      <td>27.966059</td>\n",
       "      <td>24.941944</td>\n",
       "      <td>0.103988</td>\n",
       "      <td>-0.892805</td>\n",
       "      <td>316.115011</td>\n",
       "      <td>315.553009</td>\n",
       "      <td>316.126259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp   adj close       close        high         low        open  \\\n",
       "0 2014-12-24  322.533997  322.533997  334.740997  321.356995  334.385010   \n",
       "1 2014-12-25  319.007996  319.007996  322.670013  316.958008  322.286011   \n",
       "2 2014-12-26  327.924011  327.924011  331.424011  316.627014  319.152008   \n",
       "3 2014-12-27  315.863007  315.863007  328.911011  312.630005  327.583008   \n",
       "4 2014-12-28  317.239014  317.239014  320.028015  311.078003  316.160004   \n",
       "\n",
       "     volume     ret_1   log_ret     ret_5  ...  log_vol_chg     cci_20  \\\n",
       "0  15092300 -0.035980 -0.036644  0.014759  ...    -0.093663 -55.910258   \n",
       "1   9883640 -0.010932 -0.010992 -0.033180  ...    -0.423304 -65.674105   \n",
       "2  16410500  0.027949  0.027566  0.022070  ...     0.507041 -38.540179   \n",
       "3  15185200 -0.036780 -0.037473 -0.048279  ...    -0.077600 -47.473235   \n",
       "4  11676600  0.004356  0.004347 -0.051806  ...    -0.262734 -47.802507   \n",
       "\n",
       "   plus_di_14  minus_di_14     adx_14  roll_skew_20  roll_kurt_20   typ_price  \\\n",
       "0   16.714946    30.030404  25.159419      0.074377     -0.783043  326.210663   \n",
       "1   16.168300    31.566923  25.666490      0.216627     -0.483404  319.545339   \n",
       "2   19.762835    28.927653  25.177641      0.130736     -0.852232  325.325012   \n",
       "3   17.981409    28.533062  24.999572      0.267018     -0.988402  319.134674   \n",
       "4   17.070467    27.966059  24.941944      0.103988     -0.892805  316.115011   \n",
       "\n",
       "   median_price       ohlc4  \n",
       "0    328.048996  328.254250  \n",
       "1    319.814011  320.230507  \n",
       "2    324.025513  323.781761  \n",
       "3    320.770508  321.246758  \n",
       "4    315.553009  316.126259  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('btc_features_daily.csv')\n",
    "df = pd.read_csv(data_path, parse_dates=['timestamp']).sort_values('timestamp').reset_index(drop=True)\n",
    "print(f\"Loaded {len(df):,} rows, {len(df.columns)} columns\")\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "print('Taux de valeurs manquantes (top 10):')\n",
    "print(missing.head(10))\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e71d9",
   "metadata": {},
   "source": [
    "## 2. Cible et split temporel\n",
    "On construit la cible `target_close_next` = close du lendemain (shift -1), puis split chrono (70% train, 15% val, 15% test) pour éviter le look-ahead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67333fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes -> train: 2780, val: 596, test: 596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count      3972.000000\n",
       "mean      26761.019587\n",
       "std       31230.206548\n",
       "min         178.102997\n",
       "25%        3611.820068\n",
       "50%       10972.544922\n",
       "75%       41980.804688\n",
       "max      124752.531250\n",
       "Name: target_close_next, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Créer la cible\n",
    "df = df.copy()\n",
    "df['target_close_next'] = df['close'].shift(-1)\n",
    "df = df.iloc[:-1]\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in ['timestamp', 'target_close_next']]\n",
    "X = df[feature_cols]\n",
    "y = df['target_close_next']\n",
    "\n",
    "n = len(df)\n",
    "train_end = int(n * 0.7)\n",
    "val_end = int(n * 0.85)\n",
    "X_train, y_train = X.iloc[:train_end], y.iloc[:train_end]\n",
    "X_val, y_val = X.iloc[train_end:val_end], y.iloc[train_end:val_end]\n",
    "X_test, y_test = X.iloc[val_end:], y.iloc[val_end:]\n",
    "print(f\"Split sizes -> train: {len(X_train)}, val: {len(X_val)}, test: {len(X_test)}\")\n",
    "\n",
    "y.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2abe310",
   "metadata": {},
   "source": [
    "## 3. Corrélation avec la cible\n",
    "Les features prix (close, adj close, typ_price, etc.) sont très corrélées au close du lendemain (>0.99), signalant une forte redondance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7cbf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 corrélations (absolues):\n",
      "adj close       0.999377\n",
      "close           0.999377\n",
      "typ_price       0.999328\n",
      "ohlc4           0.999259\n",
      "median_price    0.999248\n",
      "high            0.999135\n",
      "low             0.999077\n",
      "open            0.998810\n",
      "wma_10          0.998472\n",
      "ma_7            0.998334\n",
      "Name: target_close_next, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr = (\n",
    "    df.drop(columns=['timestamp'])\n",
    "      .corr()['target_close_next']\n",
    "      .drop('target_close_next')\n",
    "      .abs()\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "print('Top 10 corrélations (absolues):')\n",
    "print(corr.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9717b992",
   "metadata": {},
   "source": [
    "## 4. Modèles testés\n",
    "On teste :\n",
    "- Baseline persistance : prédire que le close de demain = close d’aujourd’hui.\n",
    "- Régression linéaire + scaling.\n",
    "- Ridge (régularisation L2).\n",
    "- Gradient Boosting Regressor.\n",
    "- Random Forest Regressor.\n",
    "\n",
    "On évalue sur le set de test (split chrono) avec MAE, RMSE, MAPE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06af4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'persistence_close',\n",
       "  'MAE': 1476.206428271812,\n",
       "  'RMSE': 2027.4586170587938,\n",
       "  'MAPE%': 1.7421122546524472},\n",
       " {'model': 'linear_reg',\n",
       "  'MAE': 1746.6667208275267,\n",
       "  'RMSE': 2289.236441680717,\n",
       "  'MAPE%': 2.015755013653118},\n",
       " {'model': 'ridge',\n",
       "  'MAE': 1745.9527526736485,\n",
       "  'RMSE': 2289.6992479917885,\n",
       "  'MAPE%': 2.01568592331959},\n",
       " {'model': 'rf',\n",
       "  'MAE': 25164.049599892835,\n",
       "  'RMSE': 31994.987486438175,\n",
       "  'MAPE%': 24.62397069216737},\n",
       " {'model': 'gboost',\n",
       "  'MAE': 27485.749910038478,\n",
       "  'RMSE': 33835.03767818492,\n",
       "  'MAPE%': 27.394445643101843}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    pct_err = np.abs((y_true - y_pred) / y_true)\n",
    "    pct_err = pct_err.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    return float(pct_err.mean() * 100)\n",
    "\n",
    "def evaluate(name, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    return {\n",
    "        'model': name,\n",
    "        'MAE': mean_absolute_error(y_test, pred),\n",
    "        'RMSE': rmse(y_test, pred),\n",
    "        'MAPE%': mape(y_test, pred),\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# Baseline persistance\n",
    "persistence_pred = X_test['close']\n",
    "results.append({\n",
    "    'model': 'persistence_close',\n",
    "    'MAE': mean_absolute_error(y_test, persistence_pred),\n",
    "    'RMSE': rmse(y_test, persistence_pred),\n",
    "    'MAPE%': mape(y_test, persistence_pred),\n",
    "})\n",
    "\n",
    "models = [\n",
    "    make_pipeline(StandardScaler(), LinearRegression()),\n",
    "    make_pipeline(StandardScaler(), Ridge(alpha=1.0)),\n",
    "    GradientBoostingRegressor(random_state=0),\n",
    "    RandomForestRegressor(n_estimators=200, random_state=0, n_jobs=-1, min_samples_leaf=2),\n",
    "]\n",
    "names = ['linear_reg', 'ridge', 'gboost', 'rf']\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    results.append(evaluate(name, model))\n",
    "\n",
    "results = sorted(results, key=lambda r: r['RMSE'])\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd78d1",
   "metadata": {},
   "source": [
    "\n",
    "### Explications des métriques utilisées\n",
    "- **MAE (Mean Absolute Error)** : erreur absolue moyenne, exprimée en unités de prix (≈ dollars). Plus petit = mieux.\n",
    "- **RMSE (Root Mean Squared Error)** : racine de l’erreur quadratique moyenne, pénalise davantage les grosses erreurs. Plus petit = mieux.\n",
    "- **MAPE (Mean Absolute Percentage Error)** : erreur absolue moyenne en pourcentage du prix réel. Plus petit = mieux, lecture directe en “% d’erreur typique”.\n",
    "\n",
    "### Lecture des résultats obtenus\n",
    "- La baseline `persistence_close` (close de demain = close d’aujourd’hui) est la meilleure : MAE ~1.5k, RMSE ~2.0k, MAPE ~1.7%.\n",
    "- `linear_reg` et `ridge` font légèrement pire : pas de gain vs recopier le prix du jour.\n",
    "- `rf` et `gboost` sont beaucoup moins bons (erreurs 10x) : ils sur-apprennent ou n’ont pas de signal utile.\n",
    "\n",
    "### Ce que cela implique\n",
    "- Le dataset est dominé par l’autocorrélation du prix : le meilleur prédicteur du prix de demain reste le prix d’aujourd’hui.\n",
    "- Les features sont très redondantes (corrélations >0.99), donc peu d’information nouvelle à extraire.\n",
    "- Pour progresser :\n",
    "  - Formuler la cible en rendement ou direction (up/down) plutôt qu’en niveau de prix.\n",
    "  - Ajouter des signaux orthogonaux (lags de retours, volatilité, sentiment, on-chain, macro) et les aligner temporellement.\n",
    "  - Utiliser une validation temporelle stricte (rolling) et plus de régularisation/contraintes pour limiter l’overfit des modèles complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32589450",
   "metadata": {},
   "source": [
    "## 5. Importance des features (Random Forest)\n",
    "Pour illustrer : importances des 10 principales features selon la Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7b7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adj close       0.289137\n",
       "typ_price       0.240868\n",
       "close           0.226125\n",
       "high            0.072490\n",
       "median_price    0.065428\n",
       "ohlc4           0.056057\n",
       "low             0.032645\n",
       "open            0.014368\n",
       "obv             0.000455\n",
       "wma_10          0.000162\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200, random_state=0, n_jobs=-1, min_samples_leaf=2\n",
    ").fit(X_train, y_train)\n",
    "importances = (\n",
    "    pd.Series(rf.feature_importances_, index=feature_cols)\n",
    "      .sort_values(ascending=False)\n",
    "      .head(10)\n",
    ")\n",
    "importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc8b68",
   "metadata": {},
   "source": [
    "Random Forest identifie surtout les niveaux de prix actuels (adj close, typ_price, close) comme prédicteurs, signe d’une forte redondance des features. Malgré sa capacité à modéliser des non-linéarités, le modèle n’apporte pas de gain : les erreurs sont bien pires que la baseline, indiquant un sur-apprentissage ou un manque de signaux exogènes. Pour améliorer : mieux contraindre le modèle, changer la cible vers des rendements/direction, et enrichir les données avec des variables orthogonales (sentiment, on-chain, macro) en validation temporelle stricte.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5738fd",
   "metadata": {},
   "source": [
    "## 6. Lecture des résultats\n",
    "- La baseline de persistance (~MAE 1.48k, RMSE ~2.03k, MAPE ~1.74%) est la meilleure. Les modèles linéaires font légèrement pire. Les arbres/boosting explosent en erreur (MAPE > 20%).\n",
    "- Le dataset est ultra redondant et dominé par le niveau de prix : les corrélations >0.99 montrent que prédire le prix de demain revient surtout à recopier celui d’aujourd’hui.\n",
    "- Les modèles non contraints sur-apprennent sans gain réel. Pour améliorer :\n",
    "  - Travailler sur des retours ou la direction (classification up/down) plutôt que sur le niveau de prix.\n",
    "  - Ajouter des features réellement orthogonales (volatilité, lags, sentiment, on-chain, macro alignés temporellement).\n",
    "  - Utiliser une validation temporelle (rolling) et plus de régularisation / features réduites (Ridge/ElasticNet, PCA sur indicateurs).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
